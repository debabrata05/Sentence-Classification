{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7768785,"sourceType":"datasetVersion","datasetId":4544622}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ntrain_data_df = pd.read_csv('/kaggle/input/siemens/train.csv')\ntest_data_df = pd.read_csv('/kaggle/input/siemens/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom bs4 import BeautifulSoup\n\ndef preprocess(text):\n    text = BeautifulSoup(str(text))\n    text = text.get_text()\n    text = text.encode(\"ascii\", \"ignore\")\n    text = text.decode()\n    text = text.replace(\"b'\", \"\")\n    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n    return text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_df['New_Sentence'] = train_data_df['New_Sentence'].apply(preprocess)\ntest_data_df['New_Sentence'] = test_data_df['New_Sentence'].apply(preprocess)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_dict = dict()\ni = 0\nfor l in train_data_df['Type'].unique():\n    label_dict[l] = i\n    i += 1\nlabels = [label_dict[i] for i in train_data_df['Type']]\ntrain_data_df['labels'] = labels\nlabel_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_data_df['New_Sentence'].to_list()\ntest_data = test_data_df['New_Sentence'].to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_df['labels'].plot(kind='hist', edgecolor='black')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(train_data, labels, test_size=0.2, random_state=1, stratify=labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Linear Model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\nX_train_vec = vectorizer.fit_transform(X_train)\nX_val_vec = vectorizer.transform(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm = SGDClassifier(loss = 'hinge', max_iter=3000, n_jobs=-1)\nsvm.fit(X_train_vec, y_train)\npredictions = svm.predict(X_val_vec)\naccuracy = accuracy_score(y_val, predictions)\nprint(\"Accuracy: {:.2f}%\".format(accuracy * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\ntrain_vec = vectorizer.fit_transform(train_data)\ntest_vec = vectorizer.transform(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm = SGDClassifier(loss = 'hinge', max_iter=3000, n_jobs=-1)\nsvm.fit(train_vec, labels)\npredictions = svm.predict(test_vec)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = []\nfor i in predictions:\n    res.append(list(label_dict.keys())[list(label_dict.values()).index(i)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = test_data_df[['Sentence_id']]\nresult['Type'] = res\nresult.to_csv('/kaggle/working/svm_result.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGBoost","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\nX_train_vec = vectorizer.fit_transform(X_train)\nX_val_vec = vectorizer.transform(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = xgb.XGBClassifier(n_estimators = 1500, max_depth = 3, use_label_encoder=False)\nmodel.fit(X_train_vec, y_train)\npredictions = model.predict(X_val_vec)\naccuracy = accuracy_score(y_val, predictions)\nprint(\"Accuracy: {:.2f}%\".format(accuracy * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\ntrain_vec = vectorizer.fit_transform(train_data)\ntest_vec = vectorizer.transform(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = xgb.XGBClassifier(n_estimators = 1500, max_depth = 3, use_label_encoder=False)\nmodel.fit(train_vec, labels)\npredictions = model.predict(test_vec)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = []\nfor i in predictions:\n    res.append(list(label_dict.keys())[list(label_dict.values()).index(i)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = test_data_df[['Sentence_id']]\nresult['Type'] = res\nresult.to_csv('/kaggle/working/XGBoost_result.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### BERT","metadata":{}},{"cell_type":"code","source":"import torch\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE","metadata":{"execution":{"iopub.status.busy":"2024-03-05T17:48:26.847478Z","iopub.execute_input":"2024-03-05T17:48:26.848177Z","iopub.status.idle":"2024-03-05T17:48:26.858742Z","shell.execute_reply.started":"2024-03-05T17:48:26.848139Z","shell.execute_reply":"2024-03-05T17:48:26.857660Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ntrain_encodings = tokenizer(X_train, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\nval_encodings = tokenizer(X_val, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nclass SentenceDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_encode = SentenceDataset(train_encodings, y_train)\nval_encode = SentenceDataset(val_encodings, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_loader = DataLoader(train_encode, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_encode, batch_size=32, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\n\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\nmodel.to(DEVICE)\n\noptim = torch.optim.Adam(model.parameters(), lr=5e-5)\nmodel.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_accuracy(model, data_loader, device):\n    with torch.no_grad():\n        correct_pred, num_examples = 0, 0\n\n        for batch_idx, batch in enumerate(data_loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs['logits']\n            predicted_labels = torch.argmax(logits, 1)\n            num_examples += labels.size(0)\n            correct_pred += (predicted_labels == labels).sum()\n\n        return correct_pred.float()/num_examples * 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 1\nfor epoch in range(NUM_EPOCHS):\n    model.train()\n    for batch_idx, batch in enumerate(train_loader):\n        input_ids = batch['input_ids'].to(DEVICE)\n        attention_mask = batch['attention_mask'].to(DEVICE)\n        labels = batch['labels'].to(DEVICE)\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss, logits = outputs['loss'], outputs['logits']\n        optim.zero_grad()\n        loss.backward()\n        optim.step()\n        if not batch_idx % 250:\n            print (f'Epoch: {epoch+1:04d}/{NUM_EPOCHS:04d} | '\n                   f'Batch {batch_idx:04d}/{len(train_loader):04d} | '\n                   f'Loss: {loss:.4f}')\n    model.eval()\n\n    with torch.set_grad_enabled(False):\n        print(f'Training accuracy: '\n              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n              f'\\nValid accuracy: '\n              f'{compute_accuracy(model, val_loader, DEVICE):.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T17:50:11.687996Z","iopub.execute_input":"2024-03-05T17:50:11.688819Z","iopub.status.idle":"2024-03-05T18:16:36.994108Z","shell.execute_reply.started":"2024-03-05T17:50:11.688782Z","shell.execute_reply":"2024-03-05T18:16:36.992974Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/2481846400.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0001/0001 | Batch 0000/1503 | Loss: 1.7815\nEpoch: 0001/0001 | Batch 0250/1503 | Loss: 0.7808\nEpoch: 0001/0001 | Batch 0500/1503 | Loss: 0.4839\nEpoch: 0001/0001 | Batch 0750/1503 | Loss: 0.5863\nEpoch: 0001/0001 | Batch 1000/1503 | Loss: 0.7698\nEpoch: 0001/0001 | Batch 1250/1503 | Loss: 0.4696\nEpoch: 0001/0001 | Batch 1500/1503 | Loss: 0.9134\nTraining accuracy: 81.98%\nValid accuracy: 78.18%\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, '/kaggle/working/BERT.pt')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T18:20:28.597425Z","iopub.execute_input":"2024-03-05T18:20:28.597838Z","iopub.status.idle":"2024-03-05T18:20:29.296473Z","shell.execute_reply.started":"2024-03-05T18:20:28.597809Z","shell.execute_reply":"2024-03-05T18:20:29.295127Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ntrain_encodings = tokenizer(train_data, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\ntrain_encode = SentenceDataset(train_encodings, train_data_df['labels'].to_list())\ntrain_loader = DataLoader(train_encode, batch_size=16, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\nmodel.to(DEVICE)\noptim = torch.optim.Adam(model.parameters(), lr=5e-5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 5\nfor epoch in range(NUM_EPOCHS):\n    for batch_idx, batch in enumerate(train_loader):\n        input_ids = batch['input_ids'].to(DEVICE)\n        attention_mask = batch['attention_mask'].to(DEVICE)\n        labels = batch['labels'].to(DEVICE)\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss, logits = outputs['loss'], outputs['logits']\n        optim.zero_grad()\n        loss.backward()\n        optim.step()\n        if not batch_idx % 250:\n            print (f'Epoch: {epoch+1:04d}/{NUM_EPOCHS:04d} | '\n                   f'Batch {batch_idx:04d}/{len(train_loader):04d} | '\n                   f'Loss: {loss:.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, '/kaggle/working/Full_BERT.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load('/kaggle/working/Full_BERT.pt')\nmodel.to(DEVICE)\nmodel.eval()\npredictions = []\n\nfor i in range(0, len(test_encodings['input_ids']), 32):\n    input_ids = test_encodings['input_ids'][i:i+32].to(DEVICE)\n    attention_masks = test_encodings['attention_mask'][i:i+32].to(DEVICE)\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_masks)\n        outputs = torch.argmax(outputs['logits'], dim=1).tolist()\n    predictions.extend(outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = []\nfor i in predictions:\n    res.append(list(label_dict.keys())[list(label_dict.values()).index(i)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = test_data_df[['Sentence_id']]\nresult['Type'] = res\nresult.to_csv('/kaggle/working/BERT_result.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}